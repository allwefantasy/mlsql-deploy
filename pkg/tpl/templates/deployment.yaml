apiVersion: apps/v1
kind: Deployment
metadata:
  annotations: {}
  name: spark-mlsql-2-0-1-3-0-0
  namespace: default
spec:
  selector:
    matchLabels:
      app: spark-mlsql-2-0-1-3-0-0
  strategy:
    rollingUpdate:
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: spark-mlsql-2-0-1-3-0-0
    spec:
      volumes:
         - name: spark-conf
           configMap:                
              name: core-site-xml
      containers:
      - name: spark-mlsql-2-0-1-3-0-0        
        args:
          - >-
            echo "/opt/spark/bin/spark-submit --master k8s://https://{{.K8sAddress}}
            --deploy-mode client    
            --executor-memory {{.ExecutorMemory}} 
            --executor-cores {{.ExecutorCoreNum}}
            --class streaming.core.StreamingApp 
            --conf spark.kubernetes.container.image=registry-vpc.cn-hangzhou.aliyuncs.com/mlsql_tech_officiial/mlsql-{{.EngineVersion}}:v3.0.0-hadoop3.2
            --conf spark.kubernetes.container.image.pullPolicy=Always 
            --conf spark.kubernetes.namespace=default                           
            --conf spark.kubernetes.executor.request.cores={{.ExecutorCoreNum}}   
            --conf spark.kubernetes.executor.limit.cores={{.ExecutorCoreNum}}                       
            --conf spark.executor.instances={{.ExecutorNum}} 
            --conf spark.driver.host=$POD_IP 
            --conf spark.sql.cbo.enabled=true 
            --conf spark.sql.adaptive.enabled=true 
            --conf spark.sql.cbo.joinReorder.enabled=true 
            --conf spark.sql.cbo.planStats.enabled=true 
            --conf spark.sql.cbo.starSchemaDetection=true 
            --conf spark.driver.maxResultSize=2g 
            --conf spark.serializer=org.apache.spark.serializer.KryoSerializer 
            --conf spark.kryoserializer.buffer.max=200m
            --conf spark.mlsql.auth.access_token={{.AccessToken}}
            --conf "\"spark.executor.extraJavaOptions=-XX:+UnlockExperimentalVMOptions -XX:+UseZGC -XX:+UseContainerSupport  -Dio.netty.tryReflectionSetAccessible=true\""  
            --conf "\"spark.driver.extraJavaOptions=-XX:+UnlockExperimentalVMOptions -XX:+UseZGC -XX:+UseContainerSupport  -Dio.netty.tryReflectionSetAccessible=true\"" 
            local:///opt/spark/streamingpro-mlsql-spark_3.0_2.12-{{.JarEngineVersion}}.jar 
            -streaming.name {{.ClusterName}} 
            -streaming.rest true 
            -streaming.thrift false 
            -streaming.platform spark 
            -streaming.enableHiveSupport true 
            -streaming.spark.service true 
            -streaming.job.cancel true             
            -streaming.driver.port 9003" | bash
        command:
          - /bin/sh
          - '-c'
        env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                fieldPath: status.podIP          
        image: 'registry-vpc.cn-hangzhou.aliyuncs.com/mlsql_tech_officiial/mlsql-{{.EngineVersion}}:v3.0.0-hadoop3.2'
        imagePullPolicy: Always
        volumeMounts:
        - name: spark-conf
          mountPath: /opt/spark/conf/
        resources:
          limits:
            cpu: {{.DriverCoreNum}}
            memory: {{.DriverMemory}}
          requests:
            cpu: {{.DriverCoreNum}}
            memory: {{.DriverMemory}}
